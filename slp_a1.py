# -*- coding: utf-8 -*-
"""slp a1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qDXX3aQbA7huVaTzn_4vUyTlpHFbi5aI
"""



import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import T5ForConditionalGeneration, T5Tokenizer
from sklearn.model_selection import train_test_split
from nltk.translate.bleu_score import sentence_bleu

# 1. Prepare the dataset (same as previous)
data = {
    "question": [
        "What is the user's full name?",
        "When was the user born?",
        "What is the user's gender?",
        "What is the user's current education qualification?",
        "Which college does the user study in?",
        "When will the user graduate?",
        "What programming languages does the user know?",
        "Which frameworks and libraries is the user familiar with?",
        "What IoT and hardware experience does the user have?",
        "Which tools and platforms does the user use?",
        "What are the user's specialized knowledge areas?",
        "What cybersecurity project has the user worked on?",
        "Which IoT projects has the user completed?",
        "What robotics project has the user built?",
        "What web hosting project has the user worked on?",
        "What award did the user win at E-Eureka 2024?",
        "Was the user a finalist in Smart India Hackathon 2024?",
        "What Taekwondo achievements does the user have?",
        "Has the user published any blogs?",
        "What upcoming blogs is the user planning to write?",
        "Which clubs is the user active in?",
        "Which events is the user interested in?",
        "What mobile phone does the user own?",
        "What earphones does the user use?",
        "Has the user purchased any computer accessories?",
        "Where can I find the user's GitHub profile?",
        "Where can I find the user's LinkedIn profile?",
        "Where can I find the user's personal website?"
    ],
    "sql_query": [
        "SELECT full_name FROM users WHERE id = 'Dharanish M';",
        "SELECT dob FROM users WHERE id = 'Dharanish M';",
        "SELECT gender FROM users WHERE id = 'Dharanish M';",
        "SELECT degree FROM users WHERE id = 'Dharanish M';",
        "SELECT college FROM users WHERE id = 'Dharanish M';",
        "SELECT graduation_year FROM users WHERE id = 'Dharanish M';",
        "SELECT programming_languages FROM skills WHERE user_id = 'Dharanish M';",
        "SELECT frameworks_libraries FROM skills WHERE user_id = 'Dharanish M';",
        "SELECT iot_hardware FROM skills WHERE user_id = 'Dharanish M';",
        "SELECT tools_platforms FROM skills WHERE user_id = 'Dharanish M';",
        "SELECT specialized_knowledge FROM skills WHERE user_id = 'Dharanish M';",
        "SELECT project_name FROM projects WHERE category = 'Cybersecurity' AND user_id = 'Dharanish M';",
        "SELECT project_name FROM projects WHERE category = 'IoT' AND user_id = 'Dharanish M';",
        "SELECT project_name FROM projects WHERE category = 'Robotics' AND user_id = 'Dharanish M';",
        "SELECT project_name FROM projects WHERE category = 'Web Hosting' AND user_id = 'Dharanish M';",
        "SELECT award FROM achievements WHERE event = 'E-Eureka 2024' AND user_id = 'Dharanish M';",
        "SELECT finalist FROM achievements WHERE event = 'SIH 2024' AND user_id = 'Dharanish M';",
        "SELECT achievements FROM sports WHERE category = 'Taekwondo' AND user_id = 'Dharanish M';",
        "SELECT title FROM blogs WHERE status = 'published' AND user_id = 'Dharanish M';",
        "SELECT title FROM blogs WHERE status = 'upcoming' AND user_id = 'Dharanish M';",
        "SELECT club_name FROM memberships WHERE user_id = 'Dharanish M';",
        "SELECT event_name FROM interests WHERE user_id = 'Dharanish M';",
        "SELECT phone_model FROM user_devices WHERE user_id = 'Dharanish M';",
        "SELECT earphone_model FROM user_devices WHERE user_id = 'Dharanish M';",
        "SELECT accessory_name FROM user_purchases WHERE category = 'Computer Accessories' AND user_id = 'Dharanish M';",
        "SELECT github_link FROM profiles WHERE user_id = 'Dharanish M';",
        "SELECT linkedin_link FROM profiles WHERE user_id = 'Dharanish M';",
        "SELECT website_link FROM profiles WHERE user_id = 'Dharanish M';"
    ]
}

# Load dataset into pandas DataFrame
df = pd.DataFrame(data)

# 2. Train-test split
X_train, X_test, y_train, y_test = train_test_split(df['question'], df['sql_query'], test_size=0.2, random_state=42)

# 3. Load Pretrained T5 Model and Tokenizer
model_name = 't5-small'
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

# Custom dataset class
class SQLDataset(Dataset):
    def __init__(self, questions, queries, tokenizer, max_length=128):
        self.questions = questions
        self.queries = queries
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.questions)

    def __getitem__(self, idx):
        question = self.questions.iloc[idx]
        sql_query = self.queries.iloc[idx]

        input_tokens = self.tokenizer(question, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)
        target_tokens = self.tokenizer(sql_query, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)

        return {
            'input_ids': input_tokens['input_ids'].squeeze(),
            'attention_mask': input_tokens['attention_mask'].squeeze(),
            'labels': target_tokens['input_ids'].squeeze()
        }

# Create DataLoader
train_dataset = SQLDataset(X_train, y_train, tokenizer)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

# 4. Train the model
def train_model():
    model.train()
    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)
    epochs = 3

    for epoch in range(epochs):
        total_loss = 0
        for batch in train_loader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            labels = batch['labels']

            # Forward pass
            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            total_loss += loss.item()

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}")

# Train the model
train_model()

# Save the model
model.save_pretrained("t5_sql_parser")

# 5. Evaluate the model
def evaluate_model():
    model.eval()
    predictions = []

    with torch.no_grad():
        for i in range(len(X_test)):
            question = X_test.iloc[i]
            input_tokens = tokenizer(question, return_tensors='pt', padding=True, truncation=True)

            # Generate SQL query
            output = model.generate(**input_tokens)
            decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)
            predictions.append(decoded_output)

    # BLEU score evaluation
    bleu_scores = []
    for pred, true in zip(predictions, y_test):
        bleu_scores.append(sentence_bleu([true.split()], pred.split()))  # Split and compute BLEU score

    avg_bleu_score = sum(bleu_scores) / len(bleu_scores)
    print(f"Average BLEU score: {avg_bleu_score:.2f}")
    return predictions

# Get the predictions
predictions = evaluate_model()

# 6. Function to respond with full details
def respond_to_query(query):
    # SQL-like data (could be from DB or JSON)
    user_data = {
        "full_name": "Dharanish M",
        "dob": "05-01-2005",
        "gender": "Male",
        "degree": "B.Tech - Artificial Intelligence & Data Science",
        "college": "karpagam college og engineering",
        "graduation_year": "2026",
        "programming_languages": ["Python","java","C++", "JavaScript"],
        "frameworks_libraries": ["TensorFlow", "PyTorch", "React", "Flask"],
        "iot_hardware": ["ESP8266", "Arduino", "Raspberry Pi"],
        "tools_platforms": ["GitHub", "GitLab", "Docker"],
        "specialized_knowledge": ["AI", "Machine Learning", "Data Science", "Embedded Systems"],
        "cybersecurity_projects": ["WiFi Jammer using ESP8266"],
        "iot_projects": ["Energy-Efficient Storage System", "Smart Home Automation"],
        "robotics_projects": ["Autonomous Robot using Raspberry Pi"],
        "web_hosting_projects": ["Personal Portfolio Website"],
        "award": "1st Prize at E-Eureka 2024",
        "si_finalist": "Yes",
        "taekwondo_achievements": ["Black Belt"],
        "published_blogs": ["ESP32 and Arduino IDE setup"],
        "upcoming_blogs": ["My Journey in AI"],
        "clubs": ["Robotics Club", "AI Club"],
        "events": ["Eureka", "Smart India Hackathon"],
        "mobile_phone": "Redmi K50i",
        "earphones": "Oppo Enco 2",
        "computer_accessories": ["Power Bank", "Hard Disk"],
        "github_link": "https://github.com/dharanish-m",
        "linkedin_link": "https://www.linkedin.com/in/dharanish-m/",
        "website_link": "https://dharanishm.com"
    }

    # Respond based on the query
    response = user_data.get(query, "Sorry, I don't have information for that query.")
    return response

# Example usage: Get full details
query = "full_name"
response = respond_to_query(query)
print(query,":",response)
query = "dob"
response = respond_to_query(query)
print(query,":",response)
query = "gender"
response = respond_to_query(query)
print(query,":",response)
query = "degree"
response = respond_to_query(query)
print(query,":",response)
query = "college"
response = respond_to_query(query)
print(query,":",response)
query = "graduation_year"
response = respond_to_query(query)
print(query,":",response)
query = "iot_projects"
response = respond_to_query(query)
print(query,":",response)

